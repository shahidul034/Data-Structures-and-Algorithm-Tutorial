{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahidul034/Data-Structures-and-Algorithm-Tutorial/blob/main/contest_bn_to_rm_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Python Libraries"
      ],
      "metadata": {
        "id": "DbUHvbEKtUME"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMkLcHXlRWnB"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] -q\n",
        "!pip install accelerate -q\n",
        "!apt install git-lfs -q\n",
        "!pip install sacrebleu -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Managing Warnings and Disabling WandB Integration"
      ],
      "metadata": {
        "id": "WAzgN1r9tmq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "0aaHEqLyVS-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understand the Dataset Structure**:  \n",
        "   Begin by inspecting the dataset to understand its structure and contents. This includes checking:\n",
        "   - Column names (`features`)\n",
        "   - Data types\n",
        "   - Number of rows (`num_rows`)"
      ],
      "metadata": {
        "id": "86W_eCjZq5bU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usoc86iJRWnE"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "raw_datasets = load_dataset(\"SKNahin/bengali-transliteration-data\")\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the Data**:  \n",
        "   Write code to clean and prepare the dataset for modeling:\n",
        "   - Handle missing values (e.g., fill, drop, or impute missing values).\n",
        "   - Normalize or scale features if required.\n",
        "   - Encode categorical data if applicable.\n",
        "   - Check for and handle duplicates or outliers.\n",
        "   - Perform feature selection if necessary.\n",
        "   - stop words removing\n",
        "   - stemminmg or lemmatization"
      ],
      "metadata": {
        "id": "AjEWIjWVqX89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets= ..."
      ],
      "metadata": {
        "id": "w7trzMKOrGjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Dataset**:  \n",
        "   - Use the `.train_test_split()` function (or similar) to divide the dataset into training and validation sets.\n",
        "   - Specify the `train_size` and use a consistent `seed` for reproducibility.\n",
        "   - Rename the test split to \"validation\" for clarity if needed."
      ],
      "metadata": {
        "id": "3KGPQzdwrK5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd4gJTfpRWnF"
      },
      "outputs": [],
      "source": [
        "split_datasets = raw_datasets[\"train\"].train_test_split(train_size='', seed='')\n",
        "split_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting a Model and Tokenizer\n",
        "\n",
        "1. **Understand the Task**:  \n",
        "   Before selecting a model, identify the task you are solving (e.g., translation, summarization, text classification). In this example, the task is **language translation** from Bengali (`bn`) to English (`en`).\n",
        "\n",
        "2. **Select a Model Checkpoint**:  \n",
        "   - Choose a pre-trained model checkpoint suitable for your task from the Hugging Face Model Hub.  \n",
        "   - Look for a model trained on your desired source and target languages or specific domains.  \n",
        "\n",
        "3. **Initialize the Tokenizer**:  \n",
        "   - Load the tokenizer corresponding to your selected model.  \n",
        "\n",
        "4. **Load the Model**:  \n",
        "   - Verify the model compatibility with your task (e.g., sequence-to-sequence models for translation).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Explore the [Hugging Face Model Hub](https://huggingface.co/models) to find the most suitable model for their specific use case."
      ],
      "metadata": {
        "id": "IUINmp1krYmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fccwABgrRWnG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
        "model_checkpoint = \"\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Understand the Preprocessing Requirements**:  \n",
        "   - Seq2Seq models, such as translation models, require input data (source text) and target data (target text).  \n",
        "   - Inputs and targets must be tokenized and truncated to a fixed `max_length` to fit the model's requirements.\n",
        "\n",
        "2. **Define the Maximum Sequence Length**:  \n",
        "   - Set a `max_length` parameter (e.g., 64) to limit the tokenized sequences for both inputs and targets.  \n",
        "   - This ensures that overly long sequences do not cause memory issues during training.\n",
        "\n",
        "3. **Create a Preprocessing Function**:  \n",
        "   - Write a function that:\n",
        "     - Reads the source and target columns from the dataset.  \n",
        "     - Tokenizes the source and target texts.  \n",
        "     - Truncates sequences that exceed the maximum length.  "
      ],
      "metadata": {
        "id": "uVrdAQkssiiU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Qq8ZhpRWnH"
      },
      "outputs": [],
      "source": [
        "max_length = \"\"\n",
        "def preprocess_function(examples):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing and Preparing the Dataset"
      ],
      "metadata": {
        "id": "ex70lN6It2C8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wawdJU-4RWnH"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = split_datasets.map(\n",
        "    ## write your code\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up a Data Collator for dynamically pads input sequences in a batch to the same length."
      ],
      "metadata": {
        "id": "nL4hKe9Dt-4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7fMjq2dRWnH"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Using Evaluation Metrics"
      ],
      "metadata": {
        "id": "dP-PgG3buEvz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM0X1o0oRWnI"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load('')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the evaluation metrics for your task\n",
        "Here are some common evaluation metrics used in Natural Language Processing (NLP):\n",
        "\n",
        "1. **Accuracy**: Measures the overall correctness of predictions.\n",
        "2. **Precision**: The proportion of correct positive predictions out of all positive predictions made.\n",
        "3. **Recall**: The proportion of true positive instances identified out of all actual positives.\n",
        "4. **F1 Score**: The harmonic mean of precision and recall, providing a balanced evaluation metric.\n",
        "5. **BLEU (Bilingual Evaluation Understudy)**: Used for evaluating the quality of machine-translated text against one or more reference translations.\n",
        "6. **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Measures the overlap of n-grams between the system and reference summaries, commonly used for summarization tasks.\n",
        "7. **METEOR (Metric for Evaluation of Translation with Explicit ORdering)**: Considers synonyms, stemming, and word order for evaluating machine translation.\n",
        "8. **chrF++**: A character n-gram F-score metric used for evaluating translation quality.\n",
        "9. **Perplexity**: Measures how well a probability model predicts a sample, often used in language modeling.\n",
        "10. **BERTScore**: Uses BERT embeddings to evaluate the similarity between predicted and reference texts.\n",
        "\n",
        "These metrics help assess the performance and effectiveness of NLP models across various tasks.\n",
        "\n",
        "https://huggingface.co/evaluate-metric\n",
        "\n",
        "https://huggingface.co/docs/evaluate/en/choosing_a_metric\n"
      ],
      "metadata": {
        "id": "evnDbpN_uLMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HkI_imiRWnI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    pass\n",
        "    ## write your code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Seq2Seq Training Arguments\n",
        "1. **Purpose of `Seq2SeqTrainingArguments`**:  \n",
        "   - `Seq2SeqTrainingArguments` is a specialized configuration class for sequence-to-sequence (Seq2Seq) tasks using the Hugging Face `Trainer`.\n",
        "   - It configures important training parameters like batch size, learning rate, number of epochs, etc., to control the behavior of the training loop.\n",
        "\n",
        "2. **Key Parameters in the Training Arguments**:\n",
        "\n",
        "   - **`output_dir`**:  \n",
        "     - The directory where the model checkpoints will be saved. In this case, it will be saved as `\"finetuned-bn-to-rm\"`.\n",
        "   \n",
        "   - **`evaluation_strategy`**:  \n",
        "     - Defines when to run evaluations. Set to `\"no\"` to disable evaluation during training.\n",
        "   \n",
        "   - **`save_strategy`**:  \n",
        "     - Specifies when to save model checkpoints. `\"epoch\"` saves checkpoints at the end of each epoch.\n",
        "   \n",
        "   - **`learning_rate`**:  \n",
        "     - The learning rate used by the optimizer. In this case, it's set to `2e-5`, which is commonly used for fine-tuning.\n",
        "   \n",
        "   - **`per_device_train_batch_size` and `per_device_eval_batch_size`**:  \n",
        "     - Batch sizes for training and evaluation. Training uses a batch size of 32, while evaluation uses a larger batch size of 64.\n",
        "   \n",
        "   - **`weight_decay`**:  \n",
        "     - Regularization to prevent overfitting, typically set to a small value like `0.01`.\n",
        "   \n",
        "   - **`save_total_limit`**:  \n",
        "     - Limits the total number of checkpoints to keep. In this case, only the last 3 checkpoints will be retained.\n",
        "   \n",
        "   - **`num_train_epochs`**:  \n",
        "     - Number of training epochs, set to 3 in this example.\n",
        "   \n",
        "   - **`predict_with_generate`**:  \n",
        "     - Ensures the model generates predictions during evaluation, rather than relying on classification logits.\n",
        "   \n",
        "   - **`fp16`**:  \n",
        "     - Enables mixed precision training for faster training with lower memory usage, set to `True` to use 16-bit floating point precision.\n",
        "\n",
        "   - **`push_to_hub`**:  \n",
        "     - Controls whether or not to upload the model to the Hugging Face Model Hub. Set to `False` to disable this behavior.\n",
        "\n",
        "https://huggingface.co/docs/transformers/v4.47.1/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n"
      ],
      "metadata": {
        "id": "VjIAjDS_v1PC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO4feIeRRWnJ"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"demo_name\",\n",
        "    evaluation_strategy='',\n",
        "    save_strategy='',\n",
        "    learning_rate='',\n",
        "    per_device_train_batch_size='',\n",
        "    per_device_eval_batch_size='',\n",
        "    weight_decay='',\n",
        "    save_total_limit='',\n",
        "    num_train_epochs='',\n",
        "    predict_with_generate='',\n",
        "    fp16='',\n",
        "    push_to_hub='',\n",
        "    ## Add more parameters if needed\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up and Using `Seq2SeqTrainer`\n",
        "\n",
        "1. **Purpose of `Seq2SeqTrainer`**:  \n",
        "   - The `Seq2SeqTrainer` class is a specialized trainer for sequence-to-sequence tasks (such as machine translation or summarization).  \n",
        "   - It integrates the model, datasets, training arguments, and metrics, providing a simple interface for training and evaluation.\n",
        "\n",
        "2. **Key Parameters in the `Seq2SeqTrainer`**:\n",
        "\n",
        "   - **`model`**:  \n",
        "     - The pre-trained or fine-tuned model you are training. This is passed as an argument to the trainer.\n",
        "   \n",
        "   - **`args`**:  \n",
        "     - The training configuration, including batch sizes, learning rate, and number of epochs, which were set up in the `Seq2SeqTrainingArguments`.\n",
        "\n",
        "   - **`train_dataset`**:  \n",
        "     - The training dataset that has been preprocessed and tokenized. In this case, it's `tokenized_datasets[\"train\"]`.\n",
        "\n",
        "   - **`eval_dataset`**:  \n",
        "     - The evaluation dataset used for validation during training. Here, it's `tokenized_datasets[\"validation\"]`.\n",
        "\n",
        "   - **`data_collator`**:  \n",
        "     - The data collator, such as `DataCollatorForSeq2Seq`, used to pad and format the batches for training. It ensures the inputs and targets are padded correctly during batch creation.\n",
        "\n",
        "   - **`tokenizer`**:  \n",
        "     - The tokenizer used for tokenizing the text. It's necessary to decode predictions during evaluation and ensure correct formatting of inputs.\n",
        "\n",
        "   - **`compute_metrics`**:  \n",
        "     - A function that computes evaluation metrics, such as BLEU score. In this case, the `compute_metrics` function is used to compute BLEU during evaluation.\n",
        "\n",
        "\n",
        "https://huggingface.co/docs/transformers/v4.47.1/en/main_classes/trainer#transformers.Seq2SeqTrainer\n"
      ],
      "metadata": {
        "id": "6z17IiKTw0JQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAmXs72rRWnJ"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset='',\n",
        "    eval_dataset='',\n",
        "    data_collator='',\n",
        "    tokenizer='',\n",
        "    compute_metrics='',\n",
        "    ## Add more parameters if needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ3ZFEN2RWnJ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating your Model and write a evaluation function\n",
        "The `compute_metrics` function that you defined earlier is called to compute metrics based on the model's predictions and the true labels from the evaluation dataset. This function is responsible for calculating evaluation metrics"
      ],
      "metadata": {
        "id": "ued7kP-ryWLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(\n",
        "    ## add parameters if needed.\n",
        ")"
      ],
      "metadata": {
        "id": "6micRBIJzOvh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}